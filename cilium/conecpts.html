<!--
title: concepts
description: 
published: true
date: 2025-12-08T21:14:14.145Z
tags: 
editor: ckeditor
dateCreated: 2025-12-08T19:18:08.405Z
-->

<h1>Overview of cilium</h1>
<h4>Overview of k8s networking</h4>
<ul>
  <li>The user provide POD CIDR that is a pool of addresses for PODs.</li>
  <li>Local Process in the nodes are able to take to the PODs on the same node.</li>
  <li>The IP addresses that come Service CIDR is more persistent than PODs IP addresses and the letter acts as VIPs</li>
  <li>Kube proxy contentiously update the IP tables &nbsp;do forward the traffic from service IPs to the pods IPs</li>
</ul>
<h4>Overview of cilium</h4>
<ul>
  <li>Act as CNI, LoadBalancer, Cluster Mesh, Ingress Controller, API gateway, Egress Gateway</li>
  <li>Features:<ul>
      <li>Security:<ul>
          <li>Network policy (L3 IPs/L4 ports)&nbsp;</li>
          <li><mark class="marker-yellow">CiliumNetworkPolicy (L7 HTTP path and method based)&nbsp;</mark></li>
          <li><mark class="marker-yellow">Encryption functionality out of the box</mark></li>
        </ul>
      </li>
      <li>Observability:<ul>
          <li><mark class="marker-yellow">Hubble: enables real-time traffic flow inspection across the clusters</mark>
            <ul>
              <li>what services are communicating with each other?</li>
              <li>how frequently:</li>
              <li>what does the service dependency graph look like?</li>
              <li>what are the HTTPs requests are being made?</li>
              <li>help in troubleshooting to faster detection of issues like (DNS, TCP, HTTP) issue</li>
              <li>Visibility to events, errors, timeouts, unanswered TCP SYN requests, and how many response codes(400,500) of HTTP are made&nbsp;</li>
              <li>Information about latency and access</li>
            </ul>
          </li>
          <li>Gather and export metrics to Promethues and Garafana</li>
        </ul>
      </li>
      <li>Service Mesh<ul>
          <li>Cilium provide most of service mesh fucntions&nbsp;</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<figure class="image image_resized" style="width:100%;"><img src="/cilium1.png"></figure>
<h4>How cilium work?</h4>
<ul>
  <li>eBPF:<ul>
      <li>eBPF allows running sandboxed application <mark class="marker-yellow">in </mark>the kernel by directly installing eBFP program that act as kernel module ( inside the kernel ) which provide:<ul>
          <li>Faster processing: no system calls are needed to the user space to the kernel</li>
          <li>Better Scaling</li>
          <li>Better visibility</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<figure class="image image_resized" style="width:41.89%;"><img src="/ebpf.png"></figure>
<ul>
  <li>Layer 3-7</li>
  <li>Identity based policies&nbsp;</li>
  <li>replace kube-proxy</li>
  <li>bandwidth control</li>
</ul>
<h4>Architercture</h4>
<ul>
  <li><mark class="marker-pink">Cilium Agent</mark> runs on ever node to listen to k8s events and API calls from the API-server and take actions<ul>
      <li>Processes the congigurations</li>
      <li>Determines how &nbsp;Pods and Service communicate</li>
      <li>Acts as load balancer</li>
      <li>Enforces network policies&nbsp;</li>
      <li>Observe and Monitors traffic</li>
      <li>Events:<ul>
          <li>new pods are sarted, stopped</li>
          <li>service endpoints changes</li>
        </ul>
      </li>
      <li>Loads the eBPF programs to the kernel</li>
    </ul>
  </li>
  <li><mark class="marker-pink">eBPF programs</mark>: L/4 traffic<ul>
      <li>control ingress and egress network traffic</li>
      <li>load balancer traffic efficiently&nbsp;</li>
      <li>enforce security policies&nbsp;</li>
    </ul>
  </li>
  <li><mark class="marker-pink">cluster Operator</mark>:<ol>
      <li>Node management</li>
      <li>cluster wide services</li>
      <li>Load balancers</li>
      <li>identity and security&nbsp;</li>
      <li>CIDR management</li>
      <li>CRD management&nbsp;</li>
      <li>Cluster Mesh</li>
      <li>IPAM</li>
      <li>cluster wide network policies</li>
      <li>high availability for cluster mesh</li>
      <li>hubble relay support</li>
    </ol>
  </li>
  <li><mark class="marker-pink">Envoy proxy</mark>: L7 traffic filtering and security<ul>
      <li>One pod per node</li>
      <li>L7 network policy (Cilium agent forward the traffic to the envoy proxy)</li>
    </ul>
  </li>
  <li><mark class="marker-pink">CRDs:</mark> used to store data and propagate state between agents</li>
  <li><mark class="marker-pink">Hubble server:</mark> &nbsp;One server per node<ul>
      <li>keeping track of all the traffic flows L 3/ 4/ 7</li>
      <li>DNS queries, packet drops, security policies</li>
      <li>Prometheus metrics</li>
    </ul>
  </li>
  <li><mark class="marker-pink">Hubble Relay</mark>: aggregates flow data from multiple Hubble servers to &nbsp;provide cluster-wide visibility</li>
</ul>
<h4>service mesh features</h4>
<ul>
  <li>Resilient connectivity between clusters</li>
  <li>L7 traffic management&nbsp;</li>
  <li>Identity based security</li>
  <li>observability and tracing</li>
  <li>Tansparency &nbsp;&lt; no code changes &gt; by using side cars o<mark class="marker-yellow">r side care less ( by implementing the eBPF program to the kernel &nbsp;L 2/ 3/ 4/) and Envoy proxy for L7 per node</mark></li>
</ul>
<figure class="image"><img src="/sm.png"></figure>
<h4>eBPF</h4>
<ul>
  <li>Extended Berkeley Packet Filter run save code inside the linux kernel without any changes in the kernel modules ! and user spaces apps can:<ul>
      <li><mark class="marker-yellow">Packet filter by using the XDP framework than runs eBPF program at the Network Interfac Card driver level !!!!!</mark></li>
      <li>XDP allows the packets to be processed before they reach the kernel stack making it mush faster than iptables and nftables</li>
      <li>eBPF use per-cpu hash table there is no rule matching in &nbsp;a table like iptables</li>
      <li>observability in real-time in the kernel space</li>
      <li>security and networking</li>
    </ul>
  </li>
</ul>
<figure class="image"><img src="/xd1p.png"></figure>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
