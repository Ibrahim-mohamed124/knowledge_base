<!--
title: Monitoiring
description: 
published: true
date: 2025-12-12T13:17:05.215Z
tags: 
editor: ckeditor
dateCreated: 2025-11-28T07:44:41.035Z
-->

<h1>OpenShift Observability</h1>
<ul>
  <li><strong>OpenShift Logging: </strong>Red&nbsp;Hat OpenShift Logging <mark class="marker-yellow">aggregates all the logs</mark> from the pods and nodes of an OpenShift cluster to a centralized location. Centralized logging improves searching, visualizing, and reporting of data.</li>
  <li><strong>OpenShift Monitoring: </strong>Red&nbsp;Hat OpenShift Monitoring<mark class="marker-yellow"> provides monitoring for core platform components</mark>.</li>
  <li><strong>Network Observability: </strong>Network observability monitors and<mark class="marker-yellow"> analyzes network traffic and helps to resolve connectivity issues.</mark></li>
  <li><strong>Distributed Tracing: </strong>Distributed tracing <mark class="marker-yellow">collects observability data in distributed systems. </mark>Distributed tracing is based on the OpenTelemetry project.</li>
</ul>
<h3>OpenShift Monitoring</h3>
<ul>
  <li>The cluster monitoring operator manages the monitoring components and ensures that they are always available and updated.</li>
  <li>The default monitoring stack does not support custom metrics for user-defined projects.</li>
  <li>Optionally, it is possible to configure custom metrics for user-defined projects and to configure persistent storage to have history of metrics.</li>
</ul>
<h3>OpenShift Monitoring Stack</h3>
<ul>
  <li>The OpenShift monitoring stack is based on the Prometheus open source project.</li>
</ul>
<figure class="image image_resized" style="width:100%;"><img src="/monitoring-architecture.svg"></figure>
<ol>
  <li>All components of the default monitoring stack are installed in the <code>openshift-monitoring</code> project and provide monitoring features for core platform components.<ul>
      <li><mark class="marker-yellow">Modifying any existing resource and creating additional </mark><code>ServiceMonitor</code>, <code>PodMonitor</code>, or <code>PrometheusRule</code> <mark class="marker-yellow">resources </mark>in the <code>openshift-monitoring</code> <mark class="marker-yellow">project is not supported</mark>.</li>
      <li><strong>Cluster Monitoring Operator:</strong>
        <ul>
          <li>The cluster monitoring operator controls the deployed monitoring components and ensures that they are always in sync with the latest version of the cluster monitoring operator.</li>
        </ul>
      </li>
      <li><strong>Prometheus Operator:</strong>
        <ul>
          <li>The Prometheus operator deploys and configures both <mark class="marker-yellow">Prometheus </mark>and <mark class="marker-yellow">Alertmanager</mark>. The operator also manages the generation of configuration targets (service monitors and pod monitors).</li>
        </ul>
      </li>
      <li><strong>Prometheus Adapter:</strong>
        <ul>
          <li><mark class="marker-yellow">The Prometheus adapter exposes cluster resources for Horizontal Pod Autoscaling (HPA).</mark></li>
        </ul>
      </li>
      <li><strong>Kube state metrics:</strong>
        <ul>
          <li>The <code>kube-state-metrics</code> converter agent <mark class="marker-yellow">exports Kubernetes objects to metrics that Prometheus can parse.</mark></li>
        </ul>
      </li>
      <li><strong>OpenShift state metrics:</strong>
        <ul>
          <li>The <code>openshift-state-metrics</code> agent is based on the <code>kube-state-metrics</code> agent and adds monitoring for OpenShift-specific resources (such as image registry metrics).</li>
        </ul>
      </li>
      <li><strong>Node exporter:</strong>
        <ul>
          <li>The <code>node-exporter</code> agent exports <mark class="marker-yellow">low-level metrics for compute nodes.</mark></li>
        </ul>
      </li>
      <li><strong>Thanos Querier:</strong>
        <ul>
          <li>Thanos Querier is a single, multitenant interface that enables <mark class="marker-yellow">aggregating and deduplicating cluster and user workload metrics.</mark></li>
        </ul>
      </li>
      <li><strong>Telemeter Client:</strong>
        <ul>
          <li>Telemeter Client sends a data portion from Prometheus instances to Red&nbsp;Hat for remote health monitoring.</li>
        </ul>
      </li>
      <li><strong>The monitoring web console:</strong>
        <ul>
          <li>The OpenShift Container Platform web console provides the <strong>Observe</strong> section to access and manage monitoring features. In the Observe section, you can access monitoring dashboards, metrics, alerts, and metrics targets.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The monitoring components for user-defined projects are installed in the <code>openshift-user-workload-monitoring</code> project.<ul>
      <li>Prometheus Operator</li>
      <li>Prometheus</li>
      <li>Thanos Ruler</li>
      <li>Alertmanager</li>
    </ul>
  </li>
</ol>
<h4>Prometheus</h4>
<ul>
  <li>Prometheus gathers and <mark class="marker-yellow">stores streams of data from the cluster as </mark><i><mark class="marker-yellow">time-series data</mark></i>. Time-series data consists of a sequence of samples, where <mark class="marker-yellow">each sample contains the following elements:</mark>
    <ul>
      <li>A timestamp</li>
      <li>A numeric value (such as an integer, float, or Boolean)</li>
      <li>A set of labels in the form of key/value pairs</li>
    </ul>
  </li>
  <li>The <mark class="marker-yellow">key/value pairs isolate groups of related values for filtering.</mark></li>
  <li>The OpenShift has three monitoring stack components to <mark class="marker-yellow">gather the metrics from the Kubernetes API</mark>: the <code>kube-state-metrics</code>, <code>openshift-state-metrics</code>, and <code>node-exporter</code> agents.</li>
  <li>Prometheus Query Language provides several <mark class="marker-yellow">operators </mark>to compute new time-series metrics like arithmetic and comparison operators, and also it contains some<mark class="marker-yellow"> built-in functions.</mark></li>
</ul>
<pre><code class="language-plaintext">node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes*100&lt;50
Shows nodes with less than 50% of available memory.

kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
Shows persistent volume claims in the pending state.</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The Red&nbsp;Hat add-on operators can define extra metrics and alerts. For example, the <code>compliance</code> operator exposes additional metrics to Prometheus. You can get a list of exposed metrics by using the following query:</li>
</ul>
<pre><code class="language-plaintext">{name=~"compliance.*"}</code></pre>
<h3>Enabling monitoring for user-defined projects</h3>
<p>&nbsp;</p>
<pre><code class="language-plaintext">oc -n openshift-monitoring edit configmap cluster-monitoring-config</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    enableUserWorkload: true </code></pre>
<h3>Exclude namespaces from the monitoring</h3>
<pre><code class="language-plaintext">oc label namespace &lt;namespace_name&gt; openshift.io/user-monitoring=false </code></pre>
<ul>
  <li>To allow a user to configure their own monitoring stack for user-defined projects</li>
</ul>
<pre><code class="language-plaintext">oc -n openshift-user-workload-monitoring adm policy add-role-to-user \
  user-workload-monitoring-config-edit &lt;user&gt; \
  --role-namespace openshift-user-workload-monitoring</code></pre>
<h2>Alerts and Notifications</h2>
<ul>
  <li>To enable Alertmanager for user-defined workloads</li>
</ul>
<pre><code class="language-plaintext">oc -n openshift-monitoring edit configmap cluster-monitoring-config</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    # ...
    alertmanagerMain:
      enableUserAlertmanagerConfig: true 
    # ...</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">oc -n openshift-user-workload-monitoring edit configmap user-workload-monitoring-config</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: user-workload-monitoring-config
  namespace: openshift-user-workload-monitoring
data:
  config.yaml: |
    alertmanager:
      enabled: true 
      enableAlertmanagerConfig: true </code></pre>
<pre><code class="language-plaintext">oc -n openshift-user-workload-monitoring get alertmanager
NAMESPACE                            NAME            VERSION   REPLICAS   READY   RECONCILED   AVAILABLE   AGE
openshift-monitoring                 main            0.27.0    2          2       True         True        8d
openshift-user-workload-monitoring   user-workload   0.27.0    2          2       True         True        41h
</code></pre>
<ul>
  <li>Use the Alerts UI to manage alerts, silences, and alerting rules.<ul>
      <li><strong>Alerting rules: </strong>Alerting rules contain <mark class="marker-yellow">a set of conditions</mark> that outline a particular state within a cluster. Alerts are triggered when those conditions are true. An alerting rule can be<mark class="marker-yellow"> assigned a severity</mark> that <mark class="marker-yellow">defines how the alerts are routed</mark>.</li>
      <li><strong>Alerts: </strong>An alert is fired when the<mark class="marker-yellow"> conditions that are defined in an alerting rule are true</mark>. Alerts notify that a set of conditions apply in an OpenShift Container Platform cluster.</li>
      <li><strong>Alert receivers: </strong>You can configure the alerting system to<mark class="marker-yellow"> route alerts to a receiver and send notifications via email, send pager notifications, or forward them to another system by using a webhook.</mark></li>
      <li><strong>Silences: </strong>A silence can be<mark class="marker-yellow"> applied to an alert to prevent sending notifications when the conditions for an alert are true</mark>. You can mute an alert after the initial notification, while you work on resolving the underlying issue.</li>
    </ul>
  </li>
  <li>Users with <code>user-workload-monitoring-config-edit</code> role in the <code>openshift-user-workload-monitoring</code> project can configure their alerts</li>
</ul>
<pre><code class="language-plaintext">oc -n &lt;namespace&gt; adm policy add-role-to-user alert-routing-edit &lt;user&gt;</code></pre>
<h3>Sending Alert Notifications for the ocp platform</h3>
<ul>
  <li>Alerts <mark class="marker-yellow">are not configured by default to be sent to any notification systems</mark>. You can configure OpenShift Container Platform to send alerts to the following receiver types:<ul>
      <li>Email</li>
      <li>PagerDuty</li>
      <li>Slack</li>
      <li>Webhook</li>
    </ul>
  </li>
  <li>The <mark class="marker-yellow">Alertmanager configuration</mark> is saved in the <code>alertmanager-main</code> secret in the <code>openshift-monitoring</code> namespace.</li>
</ul>
<pre><code class="language-plaintext">oc extract secret/alertmanager-main -n openshift-monitoring \
  --to ./ --confirm</code></pre>
<p>&nbsp;</p>
<ul>
  <li>sed script to clean the many quotes in the secret <code><strong>sed -f script.sed alertmanager.yaml</strong></code></li>
</ul>
<pre><code class="language-plaintext">#!/usr/bin/sed -f
s/"//g  
s/\&lt;\(null\)\&gt;/'\1'/g  </code></pre>
<ul>
  <li>The monitoring stack can send alerts by email through an SMTP server. The following example sends the <code>PersistentVolumeUsageNearFull</code> alerts to the <code>ocp-admins@example.com</code> email address.</li>
</ul>
<pre><code class="language-plaintext">global:
  resolve_timeout: 5m
  smtp_from: alerts@ocp4.example.com  1
  smtp_smarthost: '192.168.50.254:25'  2
  smtp_hello: localhost  3
  smtp_auth_username: smtp_training  4
  smtp_auth_password: Red_H4T@!  5
  smtp_require_tls: false  6
...output omitted...
inhibit_rules:
  ...output omitted...
receivers:
  ...output omitted...
  - name: email  7
    email_configs:  8
      - to: ocp-admins@example.com  9
route:
  group_by:
    - namespace
  group_interval: 2m  10
  group_wait: 30s
  receiver: Default
  repeat_interval: 1m  11
  routes:
    ...output omitted...
    - receiver: email  12
      match:
        alertname: PersistentVolumeUsageNearFull  13
      continue: true  14
...output omitted...</code></pre>
<p>&nbsp;</p>
<figure class="table">
  <table style="background-color:rgb(255, 255, 255);">
    <tbody>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/1.svg" alt="1"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The global SMTP host. If you do not define <code>smarthost</code> in the <code>email_configs</code> field for a receiver, then this field is the default host in use.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/2.svg" alt="2"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The global email sender address. If you do not define <code>from</code> in the <code>email_configs</code> field for a receiver, then this field is the default address in use.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/3.svg" alt="3"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The hello parameter for the SMTP connection.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/4.svg" alt="4"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The global SMTP username for optional authentication. If you do not define <code>auth_username</code> in the <code>email_configs</code> field for a receiver, then this field is the default username in use.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/5.svg" alt="5"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The global SMTP password for optional authentication. This password is used if <code>auth_password</code> is not defined in the <code>email_configs</code> field for a receiver. If you do not define <code>auth_password</code> in the <code>email_configs</code> field for a receiver, then this field is the default password in use.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/6.svg" alt="6"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">A global setting to specify whether TLS is required for SMTP. You can override this setting by using <code>require_tls</code> in the <code>email_configs</code> field for a receiver.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/7.svg" alt="7"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">An arbitrary name for the receiver. A route specifies this receiver name for a match.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/8.svg" alt="8"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">This setting indicates that the receiver sends alerts by email.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/9.svg" alt="9"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The <code>to</code> setting must be specified in the <code>email_configs</code> field, and does not have an equivalent global SMTP setting.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/10.svg" alt="10"></figure>
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/11.svg" alt="11"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">Configure the <code>group_interval</code> and <code>repeat_interval</code> fields so the alert email notifications are sent more frequently.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/12.svg" alt="12"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The receiver to use if the <code>match</code> evaluates as <code>true</code> for the alert.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/13.svg" alt="13"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">The expression to match a specific alert name.</td>
      </tr>
      <tr>
        <td style="padding:0px;vertical-align:top;">
          <figure class="image image_resized" style="width:22px;"><img src="https://rol.redhat.com/rol/static/roc/Common_Content/images/14.svg" alt="14"></figure>
        </td>
        <td style="padding:0px;vertical-align:top;">By default, every alert that enters the routing tree stops after the first matching child. The <code>continue: true</code> parameter permitts the alert to continue through the routing tree matching subsequent routes.</td>
      </tr>
    </tbody>
  </table>
</figure>
<pre><code class="language-plaintext"> oc set data secret/alertmanager-main -n openshift-monitoring \
  --from-file alertmanager.yaml</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">oc logs -f statefulset.apps/alertmanager-main -c alertmanager \
  -n openshift-monitoring</code></pre>
<h3>Alertmanager configuration for the ocp platform</h3>
<h4>Configuring external alertmanager</h4>
<ol>
  <li>Edit the cluster-monitoring-config configmap in the openshift-monitoring namespace.</li>
</ol>
<pre><code class="language-plaintext">oc -n openshift-monitoring edit configmap cluster-monitoring-config</code></pre>
<p>&nbsp; 2. Add <code>additionalAlertmanagerConfigs</code> section with configuration details under <code>data/config.yaml/prometheusK8s</code>:</p>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    prometheusK8s:
      additionalAlertmanagerConfigs:
      - scheme: https
        pathPrefix: /
        timeout: "30s"
        apiVersion: v1
        bearerToken:
          name: alertmanager-bearer-token
          key: &lt;token&gt;
        tlsConfig:
          key:
            name: alertmanager-tls
            key: &lt;key&gt;
          cert:
            name: alertmanager-tls
            key: &lt;crt&gt;
          ca:
            name: alertmanager-tls
            key: &lt;ca.crt&gt;
        staticConfigs:
        - &lt;FQDN of the external alertmanager&gt;
</code></pre>
<p>&nbsp; &nbsp;3. Disable the local Alertmanager:</p>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    alertmanagerMain:
      enabled: false</code></pre>
<p>&nbsp;</p>
<h4>Configuring Alertmanager to use secrets with receivers credentials&nbsp;</h4>
<p>&nbsp;1. &nbsp;After adding the secret in the cluster-monitoring-config configmap, the secret is mounted as a volume under <mark class="marker-yellow">/etc/alertmanager/secrets/name</mark> in the alertmanager container.</p>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    alertmanagerMain:
      secrets: 
      - test-secret-basic-auth
      - test-secret-api-token</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>The secrets must be in the same namespace as the Alertmanager object</p>
</blockquote>
<h4>Adding labels to alerts</h4>
<pre><code class="language-plaintext">apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    prometheusK8s:
      externalLabels:
        region: eu
        environment: prod</code></pre>
<h4>Configuring alert routing for default platform alerts</h4>
<ul>
  <li>Editing the default configuration in the <code>alertmanager-main</code> secret in the <code>openshift-monitoring</code> namespace.</li>
</ul>
<ol>
  <li>Extract the currently active Alertmanager configuration from the <code>alertmanager-main</code> secret and save it as a local <code>alertmanager.yaml</code> file:</li>
</ol>
<pre><code class="language-plaintext">oc -n openshift-monitoring get secret alertmanager-main --template='{{ index .data "alertmanager.yaml" }}' | base64 --decode &gt; alertmanager.yaml</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"> global:
  resolve_timeout: 5m
  http_config:
    proxy_from_environment: true &gt; to the the cluster wide proxy
route:
  group_wait: 30s  &gt; the period of alerts collecting
  group_interval: 5m &gt; the amount of time to wait before sending new group of alerts
  repeat_interval: 12h  &gt; it is recommended to be less than group_interval to make alerts repeat at each group interval
  receiver: default
  routes:
  - matchers:
    - "alertname=Watchdog"
    repeat_interval: 2m
    receiver: watchdog
   - matchers:  
     - 'severity=critical
' &gt;  Specify labels to match your alerts.
       "service=example-app"
    receiver: &lt;receiver&gt;  
receivers:
- name: default
- name: watchdog
- name: &lt;receiver&gt;
  email_configs:
    - to: myemail@example.com  1 
      from: alertmanager@example.com  2 
      smarthost: 'smtp.example.com:587'  3 
      auth_username: alertmanager@example.com   4 
      auth_password: password
      hello: alertmanager  5</code></pre>
<p>&nbsp;</p>
<blockquote>
  <p>The supported receivers are PagerDuty, webhook, email, Slack, and Microsoft Teams.</p>
</blockquote>
<p><strong>1. </strong>Specify an email address to send notifications to.</p>
<p><strong>2. </strong>Specify an email address to send notifications from.</p>
<p><strong>3. </strong>Specify the SMTP server address used for sending emails, including the port number.</p>
<p><strong>4. </strong>Specify the authentication credentials that Alertmanager uses to connect to the SMTP server. This example uses username and password.</p>
<p><strong>5. </strong>Specify the hostname to identify to the SMTP server. If you do not include this parameter, the hostname defaults to <code>localhost</code>.</p>
<p>&nbsp; 2. Apply the new configuration in the file:</p>
<pre><code class="language-plaintext">oc -n openshift-monitoring create secret generic alertmanager-main --from-file=alertmanager.yaml --dry-run=client -o=yaml |  oc -n openshift-monitoring replace secret --filename=-</code></pre>
<p>&nbsp; 3. verify the routing configuration by:</p>
<pre><code class="language-plaintext">oc exec alertmanager-main-0 -n openshift-monitoring -- amtool config routes show --alertmanager.url http://localhost:9093</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">Routing tree:
.
└── default-route  receiver: default
    ├── {alertname="Watchdog"}  receiver: Watchdog
    └── {service="example-app"}  receiver: default
        └── {severity="critical"}  receiver: team-frontend-page</code></pre>
<p>&nbsp;</p>
<ul>
  <li>You canconfigure different alert receivers for default platform alerts and user-defined alerts by using the <code>openshift_io_alert_source="platform"</code> label that is added by the Cluster Monitoring Operator to all platform alerts:<ul>
      <li>Use the <code>openshift_io_alert_source="platform"</code> matcher to match default platform alerts.</li>
      <li>Use the <code>openshift_io_alert_source!="platform"</code> or <code>'openshift_io_alert_source=""'</code> matcher to match user-defined alerts.</li>
    </ul>
  </li>
</ul>
<p>&nbsp;</p>
<h3>Configure Alertmanager for user-defined workloads</h3>
<blockquote>
  <p>There is a difference between platform alertmanager and the user-defined alertmanager configuration</p>
  <p>default &gt;&gt; alertmanager-main secret &gt;&gt;&gt; alertmanager.yaml file</p>
  <p>user-defined &gt;&gt; AlertmanagerConfig object in the user namespace</p>
  <p>There is syntax difference&nbsp;</p>
</blockquote>
<ul>
  <li>The user must have the <code>alert-routing-edit</code> cluster role to edit AlertmanagerConfig object. or edit the alertmanager-user-workload secret but you must have the cluster-admin role.</li>
</ul>
<ol>
  <li>&nbsp;Create the AlertmanagerConfig</li>
</ol>
<pre><code class="language-plaintext">apiVersion: monitoring.coreos.com/v1beta1
kind: AlertmanagerConfig
metadata:
  name: example-routing
  namespace: ns1
spec:
  route:
    receiver: default
    groupBy: [job]
  receivers:
  - name: default
    webhookConfigs:
    - url: https://example.org/post</code></pre>
<ul>
  <li>example for portworx</li>
</ul>
<pre><code class="language-plaintext"> apiVersion: monitoring.coreos.com/v1beta1
 kind: AlertmanagerConfig
 metadata:
   labels:
     app: px-backup-alert-configs
     orgId: default
     receiver_uid: 706d869c-a059-461f-8a02-33d1473d81b6
   name: px-backup-9b324756-7116-4f71-85fd-dc058b6e7955
   namespace: central
 spec:
   receivers:
   - emailConfigs:
     - from: portworx_backup@mail.ocp.ea.com
       headers:
       - key: Subject
         value: Portworx Backup - {{ if eq .GroupLabels.alertname "BackupAlert" }}Backup
           Status Alert{{ else if eq .GroupLabels.alertname "RestoreAlert" }}Restore
           Status Alert{{ else if eq .GroupLabels.alertname "ClusterAlert" }}Cluster
           Status Alert{{ else if eq .GroupLabels.alertname "BackupLocationAlert"
           }}Backup Location Status Alert{{ else if eq .GroupLabels.alertname "BackupLocationLimitedAvailabilityAlert"
           }}Backup Location Limited Availability Alert{{ else if eq .GroupLabels.alertname
           "PartialBackupAlert" }}Partial Backup Success Alert{{ else if eq .GroupLabels.alertname
           "BulkOperationFailure" }}Bulk Operation Failure Alert{{ else if eq .GroupLabels.alertname
           "LicenseExpiryAlert" }}License Expiry Alert{{ else }}Unknown Alert Type{{
           end }}
       html: '{{ template "pxc_template.tmpl" . }}'
       requireTLS: false
       smarthost: mail.ocp.ea.com:1025
       tlsConfig:
         ca: {}
         cert: {}
       to: admin@mail.ocp.ea.com
     name: px-backup-9b324756-7116-4f71-85fd-dc058b6e7955
   - name: "null"
   route:
     matchers:
     - matchType: =
       name: user_id
       value: 64af31d6-c63d-480c-aac1-3710a8024470
     receiver: "null"
     routes:
     - groupBy:
       - alertname
       - object_type
       - operation
       - user_id
       groupInterval: 30s
       groupWait: 30s
       matchers:
       - matchType: =
         name: alertname
         value: BulkOperationFailure
       receiver: px-backup-9b324756-7116-4f71-85fd-dc058b6e7955
       repeatInterval: 87600h
     - groupBy:
       - alertname
       groupInterval: 1m
       groupWait: 30s
       matchers:
       - matchType: '!='
         name: alertname
         value: BulkOperationFailure
       - matchType: =
         name: backfill
         value: ""
       receiver: px-backup-9b324756-7116-4f71-85fd-dc058b6e7955
       repeatInterval: 2208h
</code></pre>
<ul>
  <li>This is from the alertmanager.yaml &gt; instead of the camel case they user underscores&nbsp;</li>
</ul>
<pre><code class="language-plaintext">oc -n openshift-user-workload-monitoring get secret alertmanager-user-workload --template='{{ index .data "alertmanager.yaml" }}' | base64 --decode &gt; alertmanager.yaml</code></pre>
<pre><code class="language-plaintext"> oc extract secret/alertmanager-user-workload -n openshift-user-workload-monitoring --to=-
# alertmanager.yaml
"global":
  "http_config":
    "proxy_from_environment": true
"receivers":
- "name": "Default"
"route":
  "group_by":
  - "namespace"
  "receiver": "Default"
"templates":
- "/etc/alertmanager/config/*.tmpl"
</code></pre>
<pre><code class="language-plaintext">oc -n openshift-user-workload-monitoring create secret generic alertmanager-user-workload --from-file=alertmanager.yaml --dry-run=client -o=yaml |  oc -n openshift-user-workload-monitoring replace secret --filename=-</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
