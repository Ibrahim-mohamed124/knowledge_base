<!--
title: Argo Workflows
description: 
published: true
date: 2026-01-09T13:26:13.757Z
tags: 
editor: ckeditor
dateCreated: 2026-01-05T20:53:05.581Z
-->

<h1>Argo Workflows</h1>
<ul>
  <li>Is a workflow engine that execute its steps parallelly in containers that runs inside pods. These steps run as a sequence of tasks or directed acyclic graph.<ul>
      <li>Deeply integrated with kubernetes works with CI/CD, data processing, and ML pipelines</li>
    </ul>
  </li>
</ul>
<h6>Features</h6>
<ul>
  <li>workflows can be defined as a sequence of DAGs steps</li>
</ul>
<blockquote>
  <p>DAGs: A <strong>DAG</strong> is a <strong>Directed Acyclic Graph</strong>. In workflow and pipeline systems (including Argo Workflows and Tekton), it is a formal way to model <strong>task dependencies</strong>.</p>
</blockquote>
<ul>
  <li>Loops &amp; Conditions</li>
  <li>Templating</li>
  <li>Parameterization</li>
  <li>Rich UI</li>
  <li>Timeouts</li>
  <li>suspend and resume workflows</li>
  <li>Support outputting Artifacts using S3 ( Artifacts )</li>
  <li>Parallelism</li>
  <li>Daemon steps for background jobs</li>
  <li>Integrate with SDKs like Python, Golang, and Jave</li>
  <li>Exit Hooks</li>
  <li>Garbage Collection</li>
</ul>
<h3>Installation Options</h3>
<ul>
  <li>Minimal installation: core functions only for testing</li>
  <li>Production installation: fully secure setup</li>
  <li>Scopes:<ul>
      <li>Cluster wide</li>
      <li>namespace scoped controller</li>
    </ul>
  </li>
  <li>CLI</li>
</ul>
<pre><code class="language-plaintext">ARGO_WORKFLOWS_VERSION="v3.7.6"
kubectl create namespace argo
kubectl apply -n argo -f "https://github.com/argoproj/argo-workflows/releases/download/${ARGO_WORKFLOWS_VERSION}/quick-start-minimal.yaml"</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"># Detect OS
ARGO_OS="darwin"
if [[ "$(uname -s)" != "Darwin" ]]; then
  ARGO_OS="linux"
fi

# Download the binary
curl -sLO "https://github.com/argoproj/argo-workflows/releases/download/v3.7.6/argo-$ARGO_OS-amd64.gz"

# Unzip
gunzip "argo-$ARGO_OS-amd64.gz"

# Make binary executable
chmod +x "argo-$ARGO_OS-amd64"

# Move binary to path
mv "./argo-$ARGO_OS-amd64" /usr/local/bin/argo

# Test installation
argo version</code></pre>
<h3>Architecture</h3>
<ul>
  <li>Argo namespace: works as the main controllplane by using the argo server<ul>
      <li>argo server exposes REST APIs and UI</li>
      <li>Workflow controller: Core engine that orchestrate jobs in the workflow by creating pods</li>
      <li>argo server uses the k8s-api to manage cluster resources</li>
    </ul>
  </li>
  <li>User namespaces: acts as the execution plane where the actual jobs of the workflow runs</li>
  <li>Integrates with external systems like promethues and others</li>
</ul>
<figure class="image"><img src="/archflow.png"></figure>
<h4>Argo Workflow specification</h4>
<ul>
  <li>Built directly over k8s APIs using CRDs, which defined instances of it by using CRs<ul>
      <li>workflow is a structured set of tasks to do a job</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: steps-
spec:
  entrypoint: hello           # We reference our first "template" here
  arguments:
    parameters:  workflow level arguments 

  templates:
  - name: hello               # The first "template" in this Workflow, it is referenced by "entrypoint"
    steps:                    # The type of this "template" is "steps"
    - - name: hello
        template: print-message # We reference our second "template" here
        arguments:
          parameters: [{name: message, value: "hello1"}]

  - name: print-message       # The second "template" in this Workflow, it is referenced by "hello"
    inputs:
      parameters:
      - name: message
    container:                # The type of this "template" is "container"
      image: busybox
      command: [echo]
      args: ["{{inputs.parameters.message}}"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>generateName: creates a unique name for each run of the workflow</li>
  <li>spec.entrypoint: the starting point and define which template to be used first</li>
  <li>templates: define the actual task</li>
</ul>
<pre><code class="language-plaintext">argo submit file.yaml -n argo --watch</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">argo logs &lt;workflow_name&gt;</code></pre>
<p>&nbsp;</p>
<ul>
  <li>to override parameters</li>
</ul>
<pre><code class="language-plaintext">argo submit -n argo cowsay-workflow.yml --watch -p message="With great power comes great responsibility"</code></pre>
<p>&nbsp;</p>
<ul>
  <li>to start argo server UI</li>
</ul>
<pre><code class="language-plaintext">argo server --secure=false --auth-mode=server --namespace argo</code></pre>
<h3>Templates Type</h3>
<ul>
  <li>Define the steps in each step (function)</li>
  <li>The first step is defined by the entrypoint attribute</li>
  <li>Types:<ol>
      <li>Container: Most Common, executes the steps inside a container with commands and args</li>
      <li>Script: Runs a script inside a container from a file</li>
      <li>Resource: Manage k8s resources</li>
      <li>Suspend: &nbsp;pause the execution for a duration<ul>
          <li>Can be resumed from CLI, UI, and APIs</li>
        </ul>
      </li>
      <li>Container Set: &nbsp;Run multiple containers in the same pod</li>
      <li>HTTP: execute a http request</li>
      <li>Plugin: execute external plugins like integration with argocd</li>
    </ol>
  </li>
</ul>
<h3>Paramters</h3>
<ul>
  <li>Input parameters at the workflow or template levels as name and value, and cloud be overridden by CLI -p and -file params.yaml &nbsp;optiond</li>
  <li>the arguments are defined in the template using the input attribute</li>
  <li>Invocation by "{{inputs.parameters.name}}"</li>
  <li>To choose the entrypoint use --entrypoint option</li>
</ul>
<pre><code class="language-plaintext">metadata:
  generateName: cowsay-
spec:
  entrypoint: cowsay
  arguments:
    parameters:
      - name: message
        value: "a message from teh workflow argumetns section"
  templates:
    - name: cowsay
      inputs:
        parameters:
        - name: message
      container:
        image: rancher/cowsay
        command: [cowsay]
        args: ["{{inputs.parameters.message}}"]
apiVersion: argoproj.io/v1alpha1
kind: Workflow</code></pre>
<h6>Outputs</h6>
<ul>
  <li>Passing data between steps from producer to consumer</li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: output-parameter-
spec:
  entrypoint: output-parameter
  templates:
  - name: output-parameter
    steps:
    - - name: generate-parameter
        template: hello-world-to-file
    - - name: consume-parameter
        template: print-message
        arguments:
          parameters:
          # Pass the hello-param output from the generate-parameter step as the message input to print-message
          - name: message
            value: "{{steps.generate-parameter.outputs.parameters.hello-param}}"
  - name: hello-world-to-file
    container:
      image: busybox
      command: [sh, -c]
      args: ["echo -n hello world &gt; /tmp/hello_world.txt"]  # generate the content of hello_world.txt
    outputs:
      parameters:
      - name: hello-param  # name of output parameter
        valueFrom:
          path: /tmp/hello_world.txt # set the value of hello-param to the contents of this hello-world.txt
  - name: print-message
    inputs:
      parameters:
      - name: message
    container:
      image: busybox
      command: [echo]
      args: ["{{inputs.parameters.message}}"]</code></pre>
<h3>WorkflowTemplate</h3>
<ul>
  <li>Reusable workflows in namespaces</li>
</ul>
<pre><code class="language-plaintext">argo template create file.yaml</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: workflow-template-submittable
  namespace: argo
spec:
  entrypoint: print-message
  arguments:
    parameters:
      - name: message
        value: hello world
  templates:
    - name: print-message
      inputs:
        parameters:
          - name: message
      container:
        image: busybox
        command: [echo]
        args: ["{{inputs.parameters.message}}"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>Invoking one template from the workflow template</li>
</ul>
<pre><code class="language-plaintext">steps:
 - - name: test
     templateRef:
       name: workflow-template-submittable
       template: print-message
       arguments:
         parameters:
           - name: message
             value: "test"</code></pre>
<p>&nbsp;</p>
<ul>
  <li>Invoking the entire workflow template</li>
</ul>
<pre><code class="language-plaintext">spec:
  workflowTemplateRef:
    name: workflow-template-submittable</code></pre>
<p>&nbsp;</p>
<ul>
  <li>cluster wide workflow templates. In the <mark class="marker-yellow">Ref section must include clusterScope: true attribute&nbsp;</mark></li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: ClusterWorkflowTemplate
metadata:
  name: workflow-template-submittable
spec:
  entrypoint: print-message
  arguments:
    parameters:
      - name: message
        value: hello world
  templates:
    - name: print-message
      inputs:
        parameters:
          - name: message
      container:
        image: busybox
        command: [echo]
        args: ["{{inputs.parameters.message}}"]</code></pre>
<h3>Workflow spec</h3>
<ul>
  <li>Conditions<ul>
      <li>when: defined at the step level and uses arguments</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">metadata:
  generateName:  when-condition-
  namespace: argo
spec:
  entrypoint: main
  arguments:
    parameters:
      - name: environment
        value: "production"
  templates:
        - name: main
          steps:
          - - name: build
              template: build-step
            - name: test
              template:  test-step
              when: "{{workflow.parameters.environment}} != production"
            - name: deploy
              template: deploy-step
        - name: build-step
          container:
            image: alpine
            command: [sh, -c]
            args: ["echo ldteng"]
        - name: test-step
          container:
             image: alpine
             command: [sh, -c]
             args: ["echo ttesting"]
        - name: deploy-step
          container:
             image: alpine
             command: [sh, -c]
             args: ["echo kldfjsdltesting"]
apiVersion: argoproj.io/v1alpha1
kind: Workflow
</code></pre>
<ul>
  <li>Daemon<ul>
      <li>Runs a service in the background like a database or an api service</li>
      <li>automatically terminated when the workflow is finished</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
   generateName:  daemon-
spec:
  entrypoint: main
  templates:
  - name: main
    steps:
    - - name: db
        template: db
    - - name: svc
        template: svc
  - name: db
    daemon: true
    container:
      image: redis
      command: [redis-server]
  - name: svc
    container:
      image: nginx
      command: [echo "connetting to a redus"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>Timeout<ul>
      <li>sets a max duration for a step or entire workflow activeDeadlineSeconds</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: timeouts-
spec:
  activeDeadlineSeconds: 10 # terminate workflow after 10 seconds
  entrypoint: sleep
  templates:
  - name: sleep
    activeDeadlineSeconds: 5 # timeout for this step
    container:
      image: alpine:3.23
      command: [sh, -c]
      args: ["echo sleeping for 1m; sleep 60; echo done"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>OnExit handers: A script to run at the end of the workflow for tasks like cleaning up, sending notifications, or logging status.</li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: exit-handlers-
spec:
  entrypoint: intentional-fail
  onExit: exit-handler                  # invoke exit-handler template at end of the workflow
  templates:
  # primary workflow template
  - name: intentional-fail
    container:
      image: alpine:3.23
      command: [sh, -c]
      args: ["echo intentional failure; exit 1"]

  # Exit handler templates
  # After the completion of the entrypoint template, the status of the
  # workflow is made available in the global variable {{workflow.status}}.
  # {{workflow.status}} will be one of: Succeeded, Failed, Error
  - name: exit-handler
    steps:
    - - name: notify
        template: send-email
      - name: celebrate
        template: celebrate
        when: "{{workflow.status}} == Succeeded"
      - name: cry
        template: cry
        when: "{{workflow.status}} != Succeeded"
  - name: send-email
    container:
      image: alpine:3.23
      command: [sh, -c]
      args: ["echo send e-mail: {{workflow.name}} {{workflow.status}} {{workflow.duration}}"]
  - name: celebrate
    container:
      image: alpine:3.23
      command: [sh, -c]
      args: ["echo hooray!"]
  - name: cry
    container:
      image: alpine:3.23
      command: [sh, -c]
      args: ["echo boohoo!"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>RetryStrategy: &nbsp;Control retries and the delay between them</li>
</ul>
<pre><code class="language-plaintext"># This example demonstrates the use of retry back offs
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: retry-backoff-
spec:
  entrypoint: retry-backoff
  templates:
  - name: retry-backoff
    retryStrategy:
      limit: 10
      retryPolicy: "Always"
      backoff:
        duration: "1"      # Must be a string. Default unit is seconds. Could also be a Duration, e.g.: "2m", "6h", "1d"
        factor: 2
        maxDuration: "1m"  # Must be a string. Default unit is seconds. Could also be a Duration, e.g.: "2m", "6h", "1d"

    container:
      image: python:alpine3.23
      command: ["python", -c]
      # fail with a 66% probability
      args: ["import random; import sys; exit_code = random.choice([0, 1, 1]); sys.exit(exit_code)"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>to repeat a task with many items</li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: cosmic-moo-manual-
spec:
  entrypoint: moo-madness
  parallelism: 3
  templates:
  - name: moo-madness
    steps:
    -  - name: cosmic-cow
         template: moo-wisdom
         withItems:
             - "Galaxy"
             - "Universe"
             - "Cosmos"
             - "Nebula"
             - "Orbit"
             - "Comet"
             - "Star"
             - "Planet"
             - "Moon"
             - "Solar"
  - name: moo-wisdom
    container:
      image: rancher/cowsay
      command: [sh, -c]
      args: ["cowsay 'Greetings from the {{item}} System!' &amp;&amp; sleep 8"]
      args: ["cowsay 'Greetings from the {{item}} System!' &amp;&amp; sleep 8"]</code></pre>
<p>&nbsp;</p>
<ul>
  <li>to restrict the number of jobs run in the same time</li>
</ul>
<pre><code class="language-plaintext">spec:
  entrypoint: moo-madness
  parallelism: 2
  templates:</code></pre>
<p>&nbsp;</p>
<ul>
  <li>successConditions: to ensure that a job done its work correctly by validation some conditions using the resource attribute.</li>
</ul>
<h3>Artifacts</h3>
<ul>
  <li>Uses S3 bucket to store artifacts &nbsp;and the configuration details in artifacts-reposistory configmap<ul>
      <li>Generate a file from a step</li>
      <li>Read &nbsp;that file &nbsp;from the S3</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">- name: producer
  container:
   staff
  outputs:
    artifacts:
     - name: name
       path: /path
- name: consumer
  inputs:
    artifacts:
     - name: name
       path: /path</code></pre>
<p>&nbsp;</p>
<ul>
  <li>artifact garbage collection automatically delete artifacts according to delete strategy at the artifact level or globally</li>
</ul>
<pre><code class="language-plaintext">- name: producer
  container:
   staff
  outputs:
    artifacts:
     - name: name
       path: /path
       artifactGC:
         strategy: OnWorkFlowCompletion | never | OnWorkFlowDeletion</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">apiVersion: 
kind: Workflow
metadata:
  generateName: artifact-
spec:
 artifactGC:
  strategy: OnWorkFlowCompletion
 entrypoint: main
 templates:
 - name: main
   steps:
   - - name: generate
       template: generate-file
   - - name: consume
       template: consume-file
       arguments:
         artifacts:
          - name: file
            from: "{{steps.generate.output.artifacts.file}}"
 - name: generate-file
   script:
     image: busybox
     command: [sh, -c]
     source: "echo 'testin' &gt; /tmp/hello.txt"
   outputs:
     artifacts:
      - name: file
        path: /tmp/hello.txt
 - name: consume-file
   input:
    artifacts:
     - name: file
       path: /tmp/message
   container:
     image: busybox
     command: [sh, -c]
     args: ["echo '---'; echo 'recieved'; cat /tmp/message"]
   </code></pre>
<blockquote>
  <p>artifacts are compressed and archived by default but this is customizable by using the archive attribute</p>
</blockquote>
<h3>DAG</h3>
<ul>
  <li>A collection of tasks that are connected by dependencies with main two features<ul>
      <li>Directed: the flow is always has specific direction</li>
      <li>Acyclic &nbsp;(on way)</li>
    </ul>
  </li>
  <li>This approach helps in creating complex patterns like<ul>
      <li>Fan-out: on task triggers many</li>
      <li>Fan-In: many tasks trigger just one</li>
    </ul>
  </li>
</ul>
<figure class="image"><img src="/dage.png"></figure>
<ul>
  <li>depends attribute utilize OR, AND, NOT logic gates to connect more complex flows</li>
  <li>dependencies attribute is more simple one only for succeeded result</li>
  <li><mark class="marker-yellow">failFast</mark>: DAG stops by default if any task fail in it, but with this attribute it continues.</li>
</ul>
<pre><code class="language-plaintext">kind: Workflow
metadata:
  generateName: dag-
spec:
  entrypoint: main
  templates:
  - name: main
    dag:
      tasks:
      - name: A
        template: echo-message
        arguments:
          parameters: [{name: message, value: A}]
      - name: B
        dependencies: [A]
        template: echo-message
        arguments:
          parameters: [{name: message, value: B}]
      - name: C
        dependencies: [A]
        template: echo-message
        arguments:
          parameters: [{name: message, value: C}]
      - name: D
        dependencies: [B, C]
        template: echo-message
        arguments:
          parameters: [{name: message, value: D}]
  - name: echo-message
    inputs:
      parameters:
        - name: message
    container:
      image: busybox
      command: [sh, -c, "echo {{inputs.parameters.message}}"]
</code></pre>
<pre><code class="language-plaintext">spec:
  entrypoint: main
  templates:
  - name: main
    dag:
      tasks:
      - name: A
        template: succeeds
      - name: B
        template: fails
      - name: C
        depends: "A.Succeeded || B.Succeeded"
        template: echo-message
        arguments:
          parameters: [{name: message, value: C}]
      - name: D
        depends: "A.Succeeded &amp;&amp; B.Succeeded"
        template: echo-message
        arguments:
          parameters: [{name: message, value: D}]
  - name: succeeds
    container:
      image: busybox
      command: [sh, -c, "echo heyyyy"]
  - name: fails
    container:
      image: busybox
      command: [sh, -c, "echo 'nooooooooo'; exit 1"]
  - name: echo-message
    inputs:
      parameters:
        - name: message
    container:
      image: busybox
      command: [sh, -c, "echo {{inputs.parameters.message}}"]
</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
