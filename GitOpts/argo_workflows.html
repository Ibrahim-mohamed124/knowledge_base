<!--
title: Argo Workflows
description: 
published: true
date: 2026-01-06T18:00:31.374Z
tags: 
editor: ckeditor
dateCreated: 2026-01-05T20:53:05.581Z
-->

<h1>Argo Workflows</h1>
<ul>
  <li>Is a workflow engine that execute its steps parallelly in containers that runs inside pods. These steps run as a sequence of tasks or directed acyclic graph.<ul>
      <li>Deeply integrated with kubernetes works with CI/CD, data processing, and ML pipelines</li>
    </ul>
  </li>
</ul>
<h6>Features</h6>
<ul>
  <li>workflows can be defined as a sequence of DAGs steps</li>
</ul>
<blockquote>
  <p>DAGs: A <strong>DAG</strong> is a <strong>Directed Acyclic Graph</strong>. In workflow and pipeline systems (including Argo Workflows and Tekton), it is a formal way to model <strong>task dependencies</strong>.</p>
</blockquote>
<ul>
  <li>Loops &amp; Conditions</li>
  <li>Templating</li>
  <li>Parameterization</li>
  <li>Rich UI</li>
  <li>Timeouts</li>
  <li>suspend and resume workflows</li>
  <li>Support outputting Artifacts using S3 ( Artifacts )</li>
  <li>Parallelism</li>
  <li>Daemon steps for background jobs</li>
  <li>Integrate with SDKs like Python, Golang, and Jave</li>
  <li>Exit Hooks</li>
  <li>Garbage Collection</li>
</ul>
<h3>Installation Options</h3>
<ul>
  <li>Minimal installation: core functions only for testing</li>
  <li>Production installation: fully secure setup</li>
  <li>Scopes:<ul>
      <li>Cluster wide</li>
      <li>namespace scoped controller</li>
    </ul>
  </li>
  <li>CLI</li>
</ul>
<pre><code class="language-plaintext">ARGO_WORKFLOWS_VERSION="v3.7.6"
kubectl create namespace argo
kubectl apply -n argo -f "https://github.com/argoproj/argo-workflows/releases/download/${ARGO_WORKFLOWS_VERSION}/quick-start-minimal.yaml"</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"># Detect OS
ARGO_OS="darwin"
if [[ "$(uname -s)" != "Darwin" ]]; then
  ARGO_OS="linux"
fi

# Download the binary
curl -sLO "https://github.com/argoproj/argo-workflows/releases/download/v3.7.6/argo-$ARGO_OS-amd64.gz"

# Unzip
gunzip "argo-$ARGO_OS-amd64.gz"

# Make binary executable
chmod +x "argo-$ARGO_OS-amd64"

# Move binary to path
mv "./argo-$ARGO_OS-amd64" /usr/local/bin/argo

# Test installation
argo version</code></pre>
<h3>Architecture</h3>
<ul>
  <li>Argo namespace: works as the main controllplane by using the argo server<ul>
      <li>argo server exposes REST APIs and UI</li>
      <li>Workflow controller: Core engine that orchestrate jobs in the workflow by creating pods</li>
      <li>argo server uses the k8s-api to manage cluster resources</li>
    </ul>
  </li>
  <li>User namespaces: acts as the execution plane where the actual jobs of the workflow runs</li>
  <li>Integrates with external systems like promethues and others</li>
</ul>
<figure class="image"><img src="/archflow.png"></figure>
<h4>Argo Workflow specification</h4>
<ul>
  <li>Built directly over k8s APIs using CRDs, which defined instances of it by using CRs<ul>
      <li>workflow is a structured set of tasks to do a job</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: steps-
spec:
  entrypoint: hello           # We reference our first "template" here
  arguments:
    parameters:  workflow level arguments 

  templates:
  - name: hello               # The first "template" in this Workflow, it is referenced by "entrypoint"
    steps:                    # The type of this "template" is "steps"
    - - name: hello
        template: print-message # We reference our second "template" here
        arguments:
          parameters: [{name: message, value: "hello1"}]

  - name: print-message       # The second "template" in this Workflow, it is referenced by "hello"
    inputs:
      parameters:
      - name: message
    container:                # The type of this "template" is "container"
      image: busybox
      command: [echo]
      args: ["{{inputs.parameters.message}}"]</code></pre>
<ul>
  <li>generateName: creates a unique name for each run of the workflow</li>
  <li>spec.entrypoint: the starting point and define which template to be used first</li>
  <li>templates: define the actual task</li>
</ul>
<pre><code class="language-plaintext">argo submit file.yaml -n argo --watch</code></pre>
<pre><code class="language-plaintext">argo logs &lt;workflow_name&gt;</code></pre>
<ul>
  <li>to override parameters&nbsp;</li>
</ul>
<pre><code class="language-plaintext">argo submit -n argo cowsay-workflow.yml --watch -p message="With great power comes great responsibility"</code></pre>
<ul>
  <li>to start argo server UI</li>
</ul>
<pre><code class="language-plaintext">argo server --secure=false --auth-mode=server --namespace argo</code></pre>
<h3>Templates Type</h3>
<ul>
  <li>Define the steps in each step (function)</li>
  <li>The first step is defined by the entrypoint attribute&nbsp;</li>
  <li>Types:<ol>
      <li>Container: Most Common, executes the steps inside a container with commands and args</li>
      <li>Script: Runs a script inside a container from a file</li>
      <li>Resource: Manage k8s resources&nbsp;</li>
      <li>Suspend: &nbsp;pause the execution for a duration<ul>
          <li>Can be resumed from CLI, UI, and APIs</li>
        </ul>
      </li>
      <li>Container Set: &nbsp;Run multiple containers in the same pod</li>
      <li>HTTP: execute a http request</li>
      <li>Plugin: execute external plugins like integration with argocd&nbsp;</li>
    </ol>
  </li>
</ul>
<h3>Paramters</h3>
<ul>
  <li>Input parameters at the workflow or template levels as name and value, and cloud be overridden by CLI -p option&nbsp;</li>
  <li>Invocation by "{{inputs.parameters.name}}"&nbsp;</li>
</ul>
