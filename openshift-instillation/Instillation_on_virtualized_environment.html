<!--
title: Instillation on virtualized environment
description: 
published: true
date: 2025-10-28T15:05:17.127Z
tags: 
editor: ckeditor
dateCreated: 2025-10-28T11:47:16.613Z
-->

<h3>Vmware</h3>
<figure class="table">
  <table>
    <tbody>
      <tr>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">Action</td>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">Full-stack Automation</td>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">Pre-existing Infrastructure</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Build network</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Setup load balancer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Configure DNS</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Hardware or VM provisioning</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">OS installation</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Generate ignition configs</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">OS support</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer: RHCOS</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User: RHCOS</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Configure persistent storage for the internal registry</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Configure dynamic storage provider</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Installer</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">User</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Configure node provisioning and autoscaling</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Yes</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Only for providers with OpenShift Machine API support.</td>
      </tr>
    </tbody>
  </table>
</figure>
<figure class="image image_resized" style="width:100%;"><img src="/ipi-resources.svg"></figure>
<ul>
  <li>A Full Stack cluster architecture consists of the following:<ul>
      <li><strong>Bastion host (Optional)</strong>
        <ul>
          <li>The bastion host<mark class="marker-yellow"> requires network connectivity to the cloud provider API to install OpenShift and to the OpenShift API for managing OpenShift after installation.</mark></li>
        </ul>
      </li>
      <li><strong>Control plane nodes</strong>
        <ul>
          <li>Manages workloads for the compute nodes and runs services required to control the cluster.</li>
        </ul>
      </li>
      <li><strong>Compute nodes</strong>
        <ul>
          <li>Location where the actual workloads requested by Kubernetes users run and are managed.</li>
        </ul>
      </li>
      <li><strong>Infrastructure nodes</strong>
        <ul>
          <li><mark class="marker-yellow">Run core infrastructure components </mark>such as service brokers and logging.</li>
        </ul>
      </li>
      <li><strong>Temporary bootstrap node</strong>
        <ul>
          <li>A temporary node that runs a minimal Kubernetes used to deploy the OpenShift control plane. It is deleted at the end of the installation.</li>
        </ul>
      </li>
      <li><strong>Ingress load balancer</strong>
        <ul>
          <li>The virtual IP (VIP) is managed by<mark class="marker-yellow"> Keepalived</mark> and is only hosted on nodes that have a router instance. Traffic destined for the \*.apps Ingress VIP are passed directly to the router instance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<blockquote>
  <p>Keepalived is a routing software written in C. The main goal of this project is to provide simple and robust facilities for loadbalancing and high-availability to Linux system and Linux based infrastructures. Loadbalancing framework relies on well-known and widely used <a href="http://www.linux-vs.org/"><strong>Linux Virtual Server (IPVS)</strong></a> kernel module providing Layer4 loadbalancing. Keepalived implements a set of checkers to dynamically and adaptively maintain and manage loadbalanced server pool according their health. On the other hand high-availability is achieved by <a href="http://datatracker.ietf.org/wg/vrrp/"><strong>VRRP</strong></a> protocol. VRRP is a fundamental brick for router failover. In addition, Keepalived implements a set of hooks to the VRRP finite state machine providing low-level and high-speed protocol interactions. In order to offer fastest network failure detection, Keepalived implements <a href="http://datatracker.ietf.org/wg/bfd/"><strong>BFD</strong></a> protocol. VRRP state transition can take into account BFD hint to drive fast state transition. Keepalived frameworks can be used independently or all together to provide resilient infrastructures.</p>
</blockquote>
<ul>
  <li><strong>API load balancer</strong>
    <ul>
      <li>When a client creates a new request the API, HAproxy on the node hosting the API IP load balances across nodes using <mark class="marker-yellow">round robin</mark>.</li>
    </ul>
  </li>
</ul>
<h4>OpenShift Network Plug-ins for vSphere</h4>
<ul>
  <li><strong>OpenShift software defined networking (</strong><mark class="marker-yellow"><strong>SDN</strong></mark><strong>) is available for layer 2 VM connectivity.</strong></li>
  <li><strong>Networking (NSX-T):</strong>
    <ul>
      <li>an alternative for openshift software defined network that is intergrated to vshpere</li>
      <li>NSX-T creates overlay networks for <mark class="marker-yellow">VM connectivity</mark> with additional features:<ul>
          <li>micro-segmentation</li>
          <li>&nbsp;load balancers</li>
          <li>granular security policies</li>
          <li>NSX-T enables any traffic to or from the VM to be firewalled at the network layer.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>NSX Container Plug-in (NCP):</strong>
    <ul>
      <li>integrates NSX-T and OpenShift</li>
      <li>NSX manager provides visibility into which<mark class="marker-yellow"> pods are connected to which networks.</mark></li>
    </ul>
  </li>
</ul>
<h4>Cluster Storage for vshpere</h4>
<ul>
  <li><mark class="marker-yellow">vSphere Cloud Provider </mark>to support the persistent storage requirements of containers.&nbsp;</li>
  <li>VSphere cloud provider provides <mark class="marker-yellow">volume plug-ins </mark>that are accessed by the OpenShift platform, backed by<mark class="marker-yellow"> VMware vSAN</mark> or any supported vSphere Datastore. <mark class="marker-yellow">Virtual Machine File System</mark> (VMFS), <mark class="marker-yellow">Network File System</mark> (NFS) or <mark class="marker-yellow">Virtual Storage Area Network </mark>(vSAN) datastores, are available storage offerings.</li>
</ul>
<figure class="table">
  <table>
    <tbody>
      <tr>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">Volume Plug-in</td>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">ReadWriteOnce</td>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">ReadOnlyMany</td>
        <td style="border-bottom:2px solid rgb(221, 221, 221);border-top:0px;padding:8px;vertical-align:top;">ReadWriteMany</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">VMware vSphere</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">X</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">&nbsp;</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">&nbsp;</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">Cinder</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">X</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">&nbsp;</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">&nbsp;</td>
      </tr>
      <tr>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">NFS</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">X</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">X</td>
        <td style="border-top:1px solid rgb(221, 221, 221);padding:8px;vertical-align:top;">X</td>
      </tr>
    </tbody>
  </table>
</figure>
<ol>
  <li><strong>Virtual Storage Area Network (vSAN)</strong>
    <ul>
      <li>Local resources on the physical servers are <code>pooled</code>, or combined together.</li>
      <li>Each node contains a group of disks, hard drives, or solid state drives (SSDs) that defines the capacity tier.</li>
    </ul>
  </li>
</ol>
<blockquote>
  <p>A flash-based cache device such as SATA or SSD are <code>pooled</code> together across the nodes to form the vSAN data store. Attempts to write to the VSAN data store will traverse the cache first and then are flushed to the capacity tier. The data is cached as it is read into the cache tier. For example, if the same set of blocks are repeatably accessed for the VM, then you can conclude that they are staying in cache.</p>
</blockquote>
<p>&nbsp; 2. <strong>vSphere ESXi Plug-ins=vSphere Cloud Provider:</strong></p>
<ul>
  <li>Storage In-tree drivers<ul>
      <li>Formerly maintained by VMware, this is the default storage deployed when using both full-stack and pre-existing infrastructure installation methods. The plug-in creates vSphere storage using the in-tree storage drivers for vSphere included in OpenShift Container Platform, and is used when vSphere CSI drivers are not available. These drivers are supported by Red&nbsp;Hat on vSphere 6.5 and later.</li>
    </ul>
  </li>
</ul>
<blockquote>
  <p>In-tree storage drivers are older, legacy storage plugins compiled directly into the Kubernetes core, while <a href="https://www.google.com/search?q=Container+Storage+Interface+%28CSI%29&amp;rlz=1C1MMCH_enEG1173EG1173&amp;oq=storage+in-tree+drivers&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIICAEQABgWGB4yCAgCEAAYFhgeMggIAxAAGBYYHjIICAQQABgWGB4yCAgFEAAYFhgeMggIBhAAGBYYHjIICAcQABgWGB4yCAgIEAAYFhgeMgoICRAAGAoYFhge0gEIOTE4MWowajeoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8&amp;mstk=AUtExfC1mUCdcP3xXOViiCTBalD7aRiiBXwSQ1Tw60uZ4R3jVeXX0CwEchd7-HHXDbcUjNKpz95Z2HWCpS15TOF8JcMzLKyXFjXBhHK3LsaHO3Vj2Fz9woqONhi4xc7QKFOiX6Y&amp;csui=3&amp;ved=2ahUKEwj025mqj8eQAxWCX0EAHXpbHPkQgK4QegQIARAE">Container Storage Interface (CSI)</a> drivers are a modern, external, and pluggable standard for storage integration. In-tree drivers are being deprecated in favor of CSI, which provides better maintainability, a faster development cycle, and more security.</p>
</blockquote>
<ul>
  <li>vSphere CSI driver<ul>
      <li>The Container Storage Integration (CSI) provisioner is not deployed by Red&nbsp;Hat. It is a Day 2 operation deployed by the customer. The plug-in creates vSphere storage using the standard Container Storage Interface. The vSphere CSI driver is provided and supported by VMware.</li>
    </ul>
  </li>
</ul>
<h2>Installation of OpenShift on vSphere Using Full-stack Automation</h2>
<ul>
  <li>Prerequisites:<ol>
      <li>Use persistent storage with ReadWriteMany access mode for the OpenShift internal registry as a Day 2 task.</li>
      <li>Verify that the vSphere server has only one data center and one cluster. If there is more than one resource pool, then worker nodes will not provision during installation.</li>
      <li>Verify that the two DNS records, API and .apps are valid.</li>
      <li>A DHCP server is necessary for the network and provides persistent IP addresses to the cluster machines.</li>
      <li>Required vCenter Account Privileges: to create the openshfit infrastructure&nbsp;</li>
    </ol>
  </li>
</ul>
<figure class="image image_resized" style="width:100%;"><img src="/ipi-resources.svg"></figure>
<ul>
  <li>Run openshift install and provide:<ul>
      <li>SSH key when the interactive installer prompts you for the key</li>
      <li>Provide the information required by the target platform, vSphere, including the vCenter URL, username, and password.</li>
      <li>Provide values for the base domain, cluster name, and the pull secret when prompted by the the installer.</li>
    </ul>
  </li>
  <li>After the invocation of openshift-install binary:<ul>
      <li>The Red&nbsp;Hat Enterprise&nbsp;Linux CoreOS image is downloaded and used to create the virtual machines</li>
      <li>After The bootstrap and control plane virtual machines are cloned, they are automatically powered on and begin the deployment</li>
      <li>The control plane nodes create the worker nodes using the same template downloaded previously.</li>
    </ul>
  </li>
</ul>
<h4>Installing OpenShift Using Full-stack on vSphere Mandatory Requirement Checklist</h4>
<ul>
  <li>The following lists the mandatory requirements that the cluster administrator should consider before deploying an OpenShift cluster using the full-stack automation method on vSphere.</li>
</ul>
<ol>
  <li><strong>vSphere version</strong>
    <ul>
      <li>VMware vSphere 6.5</li>
      <li>VMware vSphere 6.7</li>
      <li>VMware vSphere 7.0</li>
    </ul>
  </li>
  <li><mark class="marker-pink"><strong>vSphere data center</strong></mark>
    <ul>
      <li><mark class="marker-pink">vCenter has only one data center.</mark></li>
      <li><mark class="marker-pink">vSphere data center has only one cluster.</mark></li>
    </ul>
  </li>
  <li><strong>vSphere data store</strong>
    <ul>
      <li>Create a data store for persistent volumes that is accessible by all the machine nodes in the data center for Day 1 installation.</li>
    </ul>
  </li>
  <li><strong>vSphere VM folder</strong>
    <ul>
      <li><mark class="marker-yellow">Create a new folder to contain all the cluster VMs.</mark></li>
    </ul>
  </li>
  <li><strong>Resource pool</strong>
    <ul>
      <li>The installer binary creates the machine in the default resource pool.</li>
      <li>Configuring another resource pool is <strong>NOT</strong> possible and must be considered when planning an OpenShift cluster deployment.</li>
    </ul>
  </li>
  <li><strong>Physical hosts</strong>
    <ul>
      <li>Use separate physical hosts for the cluster machines to maintain high availability of the cluster.</li>
    </ul>
  </li>
  <li><strong>VM / VM anti affinity</strong>
    <ul>
      <li><mark class="marker-yellow">Configure anti affinity rules for control plane and infra VMs when they do not reside in the same physical host.</mark></li>
    </ul>
  </li>
  <li><strong>DRS disabled</strong>
    <ul>
      <li>VMware vMotion is intended to provide live migration of virtual machines between hosts while preventing downtime. VMware <mark class="marker-yellow">Distributed Resource Scheduler (DRS) is disabled for control plane and infra worker nodes.</mark></li>
      <li>A node draining procedure is implemented before migrating compute worker nodes.</li>
      <li>In VMware DRS, virtual machines are migrated when triggered by the level of utilization on specific hosts.</li>
      <li>A VMware DRS migration might, in turn, trigger another VMware DRS migration if the OpenShift node being migrated becomes <code>NotReady</code> and the workloads on that node are scheduled on other nodes.</li>
    </ul>
  </li>
  <li><strong>Network</strong>
    <ul>
      <li>Configure DHCP, DHCP IP reservations, or static IP addresses for the cluster VMs.</li>
    </ul>
  </li>
  <li><strong>Image registry</strong>
    <ul>
      <li><mark class="marker-yellow">File storage is installed as a storage technology for high available cluster internal registry.</mark></li>
      <li>NFS on RHEL is not supported.</li>
      <li>Others NFS implementations are supported (NetApp, HPE, DELL, etc).</li>
      <li>OCS using CephFS is supported.</li>
    </ul>
  </li>
  <li><strong>Monitoring &amp; logging</strong>
    <ul>
      <li><mark class="marker-yellow">Install block storage for both monitoring and logging</mark>.</li>
    </ul>
  </li>
  <li><strong>Storage provisioning strategy</strong>
    <ul>
      <li>Choose either a static or a dynamic storage provisioning strategy.</li>
    </ul>
  </li>
  <li><strong>vSphere account</strong>
    <ul>
      <li>Create a service account in vSphere with the roles and permissions annotated on the vSphere Storage for Kubernetes Permission web page: <a href="https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/vcp-roles.html">https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/vcp-roles.html</a></li>
    </ul>
  </li>
  <li><strong>Restart policy</strong>
    <ul>
      <li>Configure the restart policy in the following order:<ul>
          <li>Stop compute nodes</li>
          <li>Stop infra nodes</li>
          <li>Stop master nodes</li>
          <li>Start master nodes</li>
          <li>Start infra nodes</li>
          <li>Start compute nodes</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><mark class="marker-yellow">Three additional worker machines (CPU: 4 cores, RAM: 24 GB, Storage: 120 GB) dedicated for infra (registry, haproxy, etc.) are provisioned</mark>.</li>
  <li>The other worker machines are dedicated for computing (compute machines).</li>
</ol>
<h4>Installing OpenShift Using Full-stack Automation on vSphere checklist</h4>
<ul class="todo-list">
  <li><label class="todo-list__label"><input type="checkbox" disabled="disabled"><span class="todo-list__label__description">Download the installer binary, oc tools, and pull secret from the Red&nbsp;Hat OpenShift Cluster Manager site.</span></label></li>
</ul>
<pre><code class="language-plaintext">sudo -i
OCP_VERSION=4.6.4
MIRROR=mirror.openshift.com/pub/openshift-v4/clients
wget \
&gt; https://{MIRROR}/ocp/${OCP_VERSION}/openshift-install-linux-${OCP_VERSION}.tar.gz
tar zxvf openshift-install-linux-${OCP_VERSION}.tar.gz \
&gt; -C /usr/bin
rm -f openshift-install-linux-${OCP_VERSION}.tar.gz
chmod +x /usr/bin/openshift-install
openshift-install version
</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">wget \
&gt; https://{MIRROR}/ocp/${OCP_VERSION}/openshift-client-linux-${OCP_VERSION}.tar.gz
tar zxvf openshift-client-linux-${OCP_VERSION}.tar.gz \
&gt; -C /usr/bin
rm -f openshift-client-linux-${OCP_VERSION}.tar.gz
chmod +x /usr/bin/oc
oc completion bash &gt;/etc/bash_completion.d/openshift
oc version
</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">su - user
ssh-keygen -f ${HOME}/.ssh/ocp46-key -N ''</code></pre>
<p>&nbsp;</p>
<ul class="todo-list">
  <li><label class="todo-list__label"><input type="checkbox" disabled="disabled"><span class="todo-list__label__description">Download the root CA certificates from vCenter and add them to your bastion VM.</span></label></li>
</ul>
<pre><code class="language-plaintext"> sudo wget vcenter.sddc.vmwaremc.com/downloads/certs/download.zip
 sudo unzip download.zip
 sudo cp certs/lin/* /etc/pki/ca-trust/source/anchors
 sudo update-ca-trust extract</code></pre>
<p>&nbsp;</p>
<ul class="todo-list">
  <li><label class="todo-list__label"><input type="checkbox" disabled="disabled"><span class="todo-list__label__description">Run the openshift-install binary to create the install-config.yaml file.</span></label></li>
</ul>
<pre><code class="language-plaintext">Create an install directory
openshift-install create install-config --dir=ocp46 &gt; --log-level=info</code></pre>
<ul class="todo-list">
  <li><label class="todo-list__label"><input type="checkbox" disabled="disabled"><span class="todo-list__label__description">Input values when prompted by the installer binary.</span></label></li>
</ul>
<pre><code class="language-plaintext">? SSH Public Key /user/.ssh/ocp4ipi.pub
? Platform vsphere
? vCenter  vcenter.vmwarecloud.com
? Usernanme  cloudadmin@vmclocal.com
Info connecting to vcenter vcenter.vmwarecloud.com
Info Defaulting to only available datacenter: SDDC
Info Defaulting to only available cluster: cluster1
? Default Datastore: WorkloadData
? Network network-segment1
? Virtual IP Address for API 192.168.1.100
? Virtual IP Address for Ingress 192.168.1.110
? Base Domain example.com
? Cluster Name ocp4
? Pull Secret ...output omitted.</code></pre>
<ul class="todo-list">
  <li><label class="todo-list__label"><input type="checkbox" disabled="disabled"><span class="todo-list__label__description">Run the installer binary to create the cluster.</span></label></li>
</ul>
<pre><code class="language-plaintext">openshift-install create cluster --dir=ocp46 \
&gt; --log-level=debug</code></pre>
