<!--
title: Chapter_Four ~ Water
description: 
published: true
date: 2025-10-20T08:57:45.802Z
tags: 
editor: ckeditor
dateCreated: 2025-10-19T11:32:32.884Z
-->

<h3>RHACM Observability Components</h3>
<ul>
  <li>Prometheus: time-series data data collection</li>
  <li>Thanos: A toolkit of components that<mark class="marker-yellow"> gathers data from multiple Prometheus instances</mark> that are running on different OpenShift clusters, and enables global querying. You can use any<mark class="marker-yellow"> S3-compatible storage for long-term storage of Prometheus data.</mark></li>
  <li>Alertmanager: A tool to manage and <mark class="marker-yellow">receive alerts from Prometheus.</mark></li>
</ul>
<figure class="image"><img src="/obs-arch.png"></figure>
<h4>components&nbsp;</h4>
<ol>
  <li><code>multiclusterhub-operator</code> pod: deploys the <code>multicluster-observability-operator</code> pod by default</li>
  <li><code>multicluster-observability-operator: </code>sends hub cluster data to the managed clusters.<ul>
      <li>Watches for new managed clusters and automatically deploys metric and alert collection services to the managed clusters.</li>
    </ul>
  </li>
  <li><code>observability-endpoint-operator</code> pod: automatically deployed to each imported or created managed cluster. This controller starts a metrics collector that collects and sends the data<mark class="marker-yellow"> from OpenShift Prometheus</mark> to the RHACM hub cluster.</li>
  <li>observability add-on controller: API server that automatically updates the log of the managed clusters.</li>
  <li>Thanos Compactor:<ul>
      <li>ensures that queries are performing well by using the retention configuration and compaction of the data in storage.</li>
      <li>Deployed by <code>multicluster-observability-operator</code></li>
    </ul>
  </li>
  <li>Grafana: visualization</li>
</ol>
<h3>Configuration</h3>
<ul>
  <li>The RHACM observability service is always installed in the hub cluster, although it is not enabled by default, due to the requirements for persistent storage, CPU, and memory.</li>
</ul>
<h4>Prerequisites for the Observability Service</h4>
<p>You must meet the following conditions to enable the observability service:</p>
<ul>
  <li>A user with the cluster administrator role, the <code>open-cluster-management:cluster-manager-admin</code> role, or an S3 administrator</li>
  <li>To define a storage class in the <code>MultiClusterObservability</code> custom resource, if no default storage class is specified</li>
  <li>To have direct network access to the hub cluster</li>
  <li>To configure an object store to create a storage solution. RHACM supports Amazon Web Services S3, Google Cloud Storage, and Red&nbsp;Hat OpenShift Data Foundation, among other cloud providers.</li>
  <li>The observability components require 2701&nbsp;m CPU and 11972&nbsp;Mi memory to enable the observability service.</li>
</ul>
<pre><code class="language-plaintext"> oc create namespace open-cluster-management-observability
 DOCKER_CONFIG_JSON=oc extract  secret/multiclusterhub-operator-pull-secret \
   -n open-cluster-management --to=-
   or
 DOCKER_CONFIG_JSON=oc extract   secret/pull-secret -n openshift-config --to=-
 oc create secret generic multiclusterhub-operator-pull-secret \
  -n open-cluster-management-observability \
  --from-literal=.dockerconfigjson="$DOCKER_CONFIG_JSON" \
  --type=kubernetes.io/dockerconfigjson</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The RHACM observability service needs a persistent object store. The following YAML example defines an <code>ObjectBucketClaim</code> named <code>thanos-obc</code> that uses the <code>openshift-storage.noobaa.io</code> storage class that<mark class="marker-yellow"> Red&nbsp;Hat OpenShift Data Foundation provides.</mark></li>
  <li>Red&nbsp;Hat OpenShift Data Foundation creates, with the same name, <mark class="marker-yellow">a matching secret and a configuration map, which contain the bucket information and credentials.</mark></li>
</ul>
<pre><code class="language-plaintext">apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim

metadata:
  name: thanos-obc
  namespace: open-cluster-management-observability
spec:
  storageClassName: openshift-storage.noobaa.io
  generateBucketName: observability-bucket</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext">oc extract --to=- cm/thanos-obc \
  -n open-cluster-management-observability
# BUCKET_REGION

# BUCKET_SUBREGION

# BUCKET_HOST
s3.openshift-storage.svc
# BUCKET_NAME
thanos-obc-b2cdf931-0ec5-41a9-9b31-033d360d3a38
# BUCKET_PORT
443</code></pre>
<p>&nbsp;</p>
<pre><code class="language-plaintext"> oc extract --to=- secret/thanos-obc \
  -n open-cluster-management-observability
# AWS_SECRET_ACCESS_KEY
MWykFQTUVUHLw3Lgjvts+WUBu2QH6hF1XLuXYYsR
# AWS_ACCESS_KEY_ID
Z9VYaOjvJVveQ1Az4rkX</code></pre>
<p>&nbsp;</p>
<ul>
  <li>Create the <code>thanos-object-storage</code> secret within the <code>open-cluster-management-observability</code> namespace by using the information from the configuration map and the credentials from the secret.</li>
</ul>
<pre><code class="language-plaintext">apiVersion: v1
kind: Secret
metadata:
  name: thanos-object-storage
  namespace: open-cluster-management-observability
type: Opaque
stringData:
  thanos.yaml: |
    type: s3
    config:
      bucket: thanos-obc-b2cdf931-0ec5-41a9-9b31-033d360d3a38
      endpoint: s3.openshift-storage.svc
      insecure: true
      access_key: Z9VYaOjvJVveQ1Az4rkX
      secret_key: MWykFQTUVUHLw3Lgjvts+WUBu2QH6hF1XLuXYYsR</code></pre>
<p>&nbsp;</p>
<ul>
  <li>To enable the observability service, you must create a <code>MultiClusterObservability</code> custom resource instance in the <code>open-cluster-management-observability</code> namespace. The <code>MultiClusterObservability</code> object requires a secret that contains the credentials of the S3 bucket storage.</li>
</ul>
<pre><code class="language-plaintext">apiVersion: observability.open-cluster-management.io/v1beta2
kind: MultiClusterObservability
metadata:
  name: observability
spec:
  enableDownsampling: true 
  observabilityAddonSpec: 
    enableMetrics: true 
    interval: 30
  storageConfig: 
    metricObjectStorage: 
      key: thanos.yaml
      name: thanos-object-storage 
    alertmanagerStorageSize: 1Gi 
    compactStorageSize: 20Gi 
    receiveStorageSize: 20Gi 
    ruleStorageSize: 1Gi 
    storeStorageSize: 10Gi 
    storageClass: ocs-external-storagecluster-ceph-rbd 12
  nodeSelector: 
    node-role.kubernetes.io/infra:</code></pre>
<p>&nbsp;</p>
<ul>
  <li>The creation of the <code>MultiClusterObservability</code> resource creates the pods for Thanos, Alertmanager, and Grafana in the <code>open-cluster-management-observability</code> namespace.</li>
</ul>
<h3>Observability Service Customizations in RHACM</h3>
<h5>Configuring the Multicluster Observability Custom Resource</h5>
<ul>
  <li><code>MultiClusterObservability</code> custom resource contains all the required parameters to configure the observability service, such as the persistent storage for Thanos and Alertmanager, the metrics retention policy, and the number of replicas of different components.</li>
</ul>
<pre><code class="language-plaintext">apiVersion: observability.open-cluster-management.io/v1beta2
kind: MultiClusterObservability
metadata:
  name: observability
spec:
  enableDownsampling: true
  observabilityAddonSpec:
    enableMetrics: true
    interval: 30
  advanced:
      receive:
         replicas: 6
...output omitted...</code></pre>
<h4>Prometheus Rules</h4>
<ul>
  <li>Prometheus supports two types of rules that can be configured and evaluated at regular intervals: <mark class="marker-yellow">recording rules and alerting rules.</mark>
    <ol>
      <li><strong>Recording rules:</strong></li>
    </ol>
  </li>
</ul>
<blockquote>
  <p>Recording rules allow you to <strong>precompute PromQL expressions</strong> and store the results as new time series. These precomputed metrics can then be queried just like any other metric, making dashboards and alerts faster and more efficient.</p>
</blockquote>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;â€“ requires a <code>record</code> field for the name of the output time series, an <code>expr</code> field for the PromQL expression to evaluate, and an optional labels field for additional labels.</p>
<pre><code class="language-plaintext">- record: code:prometheus_http_requests_total:sum
  expr: sum by (code) (prometheus_http_requests_total)
  labels:
    env: stage</code></pre>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2. &nbsp;<strong>Alerting rules:</strong></p>
<blockquote>
  <p><i>Alerting rules</i> enable you to define conditions for alerts based on Prometheus expressions, and to receive notifications when these conditions are met.</p>
</blockquote>
<pre><code class="language-plaintext">- alert: HighRequestLatency
  expr: job:request_latency_seconds:mean5m{job="myjob"} &gt; 0.5
  for: 10m
  keep_firing_for: 5m
  labels:
    severity: page
  annotations:
    summary: High request latency</code></pre>
<h4>RHACM Metrics</h4>
<ul>
  <li>The RHACM observability service provides a set of default metrics; the service receives in-cluster platform metrics from Prometheus, and federates a subset of the metrics into Thanos.</li>
  <li><code>observability-metrics-allowlist</code> configuration map within the <code>open-cluster-management-observability</code> namespace:&nbsp;<ul>
      <li>Stores the default metrices</li>
      <li>Stores a set of recording rules</li>
      <li>Cannot be modified</li>
    </ul>
  </li>
  <li>RHACM Custom Metrics:<ul>
      <li>The metrics can be exported as platform metrics or as user workload metrics.&nbsp;</li>
      <li>Needs a <code>observability-metrics-custom-allowlist</code> configuration map within the <code>open-cluster-management-observability</code> namespace. After the configmap creation the <code>metrics-collector-deployment</code> pod restarts in the <code>open-cluster-management-observability</code> namespace.</li>
      <li>Applying <code>observability-metrics-custom-allowlist</code> configuration map on a managed cluster in the <code>open-cluster-management-addon-observability</code> namespace will collect metrics from only this managed cluster.</li>
      <li>To add user workload metrics, set the namespace to capture the metric in the configuration map.&nbsp;</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">kind: ConfigMap
apiVersion: v1
metadata:
  name: observability-metrics-custom-allowlist
  namespace: monitored_namespace &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; the namespace to be monitored 
data:
  uwl_metrics_list.yaml: &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; user workload uwl
    names: 
      - sample_metrics</code></pre>
<h4>RHACM Alerts</h4>
<ul>
  <li><code>thanos-ruler-default-rules</code> configuration map within the <code>open-cluster-management-observability</code> namespace<ul>
      <li>Stores default alerting rules</li>
    </ul>
  </li>
  <li>RHACM custom alerts:<ul>
      <li>Applying the <code>thanos-ruler-custom-rules</code> configuration map within the <code>open-cluster-management-observability</code> namespace. Creating the configuration map causes the <code>observability-thanos-rule</code> pods to restart in the <code>open-cluster-management-observability</code> namespace.</li>
    </ul>
  </li>
</ul>
<pre><code class="language-plaintext">kind: ConfigMap
apiVersion: v1
metadata:
  name: thanos-ruler-custom-rules
  namespace: open-cluster-management-observability
data:
  custom_rules.yaml: | 
    groups: 
      - name: cluster-health
        rules:
        - alert: ClusterCPUReq-70 
          annotations:
            summary: Notify when CPU requests on a cluster are greater than the defined utilization limit
            description: "The cluster has a high CPU usage: {{ $value }} core for {{ $labels.cluster }} {{ $labels.clusterID }}." 
          expr: | 
            sum(namespace_cpu:kube_pod_container_resource_requests:sum) by (clusterID, cluster) / sum(kube_node_status_allocatable{resource="cpu"}) by (clusterID, cluster) &gt; 0.7
          for: 5s 
          labels:
            severity: critical</code></pre>
<h4>Grafana Dashboards in RHACM</h4>
<ul>
  <li>the <code>MultiClusterObservability</code> custom resource creates a Grafana console with more than 15 dashboards. These dashboards are stored in <code>ConfigMap</code> objects in the <code>open-cluster-management-observability</code> namespace that have the <code>grafana-dashboard-</code> prefix to learn the definitions of the dashboards.</li>
</ul>
<h4>Forwarding Metrics to External Services</h4>
<ul>
  <li>Override the <code>alertmanager-config</code> secret in the <code>open-cluster-management-observability</code> namespace to add integrations or to configure routes for Alertmanager.</li>
</ul>
<pre><code class="language-plaintext">...output omitted...
route:
  receiver: 'slack-notifications'
  group_by: [alertname, datacenter, app]

receivers:
- name: 'slack-notifications'
  slack_configs:
  - channel: '#alerts'
    text: 'https://internal.myorg.net/wiki/alerts/{{ .GroupLabels.app }}/{{ .GroupLabels.alertname }}'</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
